## 데이터 로딩과 저장, 파일 형식

```python
a,b,c,d,message
1,2,3,4,hello
5,6,7,8,world
9,10,11,12,foo
```

위와 같은 파일을 읽어올때 read_csv는 물론 `read_table(sep=",")`와 같이 구분자로 쉼표를 지정해서 읽어올 수 있음



**고정된 구분자 없이 공백이나 다른  패턴으로 필드를 구분해놓은 경우**

```python
['            A         B         C\n',
 'aaa -0.264438 -1.026059 -0.619500\n',
 'bbb  0.927272  0.302904 -0.032399\n',
 'ccc -0.264273 -0.386314 -0.217601\n',
 'ddd -0.871858 -0.348382  1.100491\n']
```

```python
import pandas as pd

df = pd.read_csv("examples/ex3.txt", sep="\s+")
# pd.read_table("examples/ex3.txt", sep="\s+")
print(df)

            A         B         C
aaa -0.264438 -1.026059 -0.619500
bbb  0.927272  0.302904 -0.032399
ccc -0.264273 -0.386314 -0.217601
ddd -0.871858 -0.348382  1.100491
```

정규 표현식 \s+를 이용해서 처리



**불필요한 데이터가 포함된 경우**

```python
# hey!
a,b,c,d,message
# just wanted to make things more difficult for you
# who reads CSV files with computers, anyway?
1,2,3,4,hello
5,6,7,8,world
9,10,11,12,foo
```

```python
import pandas as pd

df = pd.read_csv("examples/ex4.csv", skiprows=[0, 2, 3])
print(df)

   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo
```

skiprows를 이용해 불필요한 행을 제거하고 읽어옴



텍스트 파일을 조금씩 읽어오기

```python
import pandas as pd

df = pd.read_csv("examples/ex6.csv", nrows=5)
print(df)

        one       two     three      four key
0  0.467976 -0.038649 -0.295344 -1.824726   L
1 -0.358893  1.404453  0.704965 -0.200638   B
2 -0.501840  0.659254 -0.421691 -0.057688   G
3  0.204886  1.074134  1.388361 -0.982404   R
4  0.354628 -0.133116  0.283763 -0.837063   Q
```

nrows를 이용해 파일전체를 읽어오는 대신 처음 몇 줄만 읽어옴

```python
df = pd.read_csv("examples/ex6.csv", chunksize=1000)
for piece in df:
    print(piece)
```

<img src="https://user-images.githubusercontent.com/58063806/116989412-aa1a5f80-ad0c-11eb-9a82-ae7730a378c5.png" width=30% />

chunksize를 이용해 파일을 여러 조각으로 나누어서 읽어옴 (위의 경우에는 10000개의 row로 구성된 데이터를 1000개의 row로 구성된 데이터 10개로 읽어옴)

> - 대용량의 데이터를 읽어올때 유용
> - 데이터의 용량이 클 때 데이터를 한번에 읽어오기보다 여러개로 나누어서 읽어와서 이것들을 합치는 것이 더 효율적 



#### JSON 데이터

- 웹브라우저와 다른 애플리케이션이 HTTP 요청으로 데이터를 보낼 때 널리 사용하는 표준 파일 형식 중 하나
- CSV 같은 표 형식의 텍스트보다 좀 더 유연한 데이터 형식

```python
obj = """
{"name": "Wes",
"places_lived": ["United States", "Spain", "Germany"],
"pet": null,
"siblings": [{"name": "Scott", "age": 30, "pets": ["Zues", "Zuko"]},
{"name": "Katie", "age": 38, "pets": ["Sixes", "Stache", "Cisco"]}]
}"""
```

```python
import json

result = json.loads(obj)
result

{'name': 'Wes',
 'places_lived': ['United States', 'Spain', 'Germany'],
 'pet': None,
 'siblings': [{'name': 'Scott', 'age': 30, 'pets': ['Zues', 'Zuko']},
  {'name': 'Katie', 'age': 38, 'pets': ['Sixes', 'Stache', 'Cisco']}]}

# 파이썬 객체를 JSON 형태로 변환
asjson = json.dumps(result)
asjson

'{"name": "Wes", "places_lived": ["United States", "Spain", "Germany"], "pet": null, "siblings": [{"name": "Scott", "age": 30, "pets": ["Zues", "Zuko"]}, {"name": "Katie", "age": 38, "pets": ["Sixes", "Stache", "Cisco"]}]}'
```

```python
# examples/example.json
[{"a": 1, "b": 2, "c": 3},
 {"a": 4, "b": 5, "c": 6},
 {"a": 7, "b": 8, "c": 9}]

data = pd.read_json("examples/example.json")
data             

   a  b  c
0  1  2  3
1  4  5  6
2  7  8  9

print(data.to_json())
{"a":{"0":1,"1":4,"2":7},"b":{"0":2,"1":5,"2":8},"c":{"0":3,"1":6,"2":9}}
```

별다른 옵션이 주어지지 않았을 경우 read_json은 JSON 배열에 담긴 각 객체를 테이블의 로우로 간주

#### XML & HTML (웹 스크래핑)

- XML은 계층적 구조와 메타데이터를 포함하는 중첩된 데이터 구조를 지원하는 데이터 형식
  - HTML과 구조적으로 유사하지만 XML이 조금 더 범용적

```python
tables = pd.read_html("examples/fdic_failed_bank_list.html")

len(tables)
# 1
failures = tables[0]
failures.head()
```

<img src="https://user-images.githubusercontent.com/58063806/116991733-f6b36a00-ad0f-11eb-8e87-ec62c21765d6.png" width=80% />

read_html 함수는 lxml이나 Beautiful Soup 같은 라이브러리를 사용, 기본적으로 <table> 태그 안에 있는 모든 표 형식의 데이터 파싱을 시도해서 Dataframe 객체의 리스트에 저장

**XML 파일**

<img src="https://user-images.githubusercontent.com/58063806/116993237-2499ae00-ad12-11eb-9a27-b9ea917090d3.png" width=50% />

```python
from lxml import objectify

path = "datasets/mta_perf/Performance_MNR.xml"
parsed = objectify.parse(open(path))
root = parsed.getroot()
```

lxml.objectify로 파일을 파싱한 후 getroot 함수를 이용해서 XML 파일의 루트 노드에 대한 참조를 얻어옴

```python
data = []

skip_fields = ["PARENT_SEQ", "INDICATOR_SEQ", "DESIRED_CHANGE", "DECIMAL_PLACES"]

for elt in root.INDICATOR:
    el_data = {}
    for child in elt.getchildren():
        if child.tag in skip_fields:
            continue
        el_data[child.tag] = child.pyval
    data.append(el_data)
    
perf = pd.DataFrame(data)
perf.head()
```

root.INDICATOR를 이용해서 XML 엘리먼트를 끄집어 내고 각각의 항목에 대해 몇몇 태그를 제외하고 태그 이름을 키 값으로 하는 딕셔너리를 생성

<img src="https://user-images.githubusercontent.com/58063806/116993724-d0db9480-ad12-11eb-847a-03037ab8dcca.png" width=80% />

#### 이진 데이터 형식

- 데이터를 효율적으로 저장하는 가장 손쉬운 방법은 파이썬에 기본으로 내장되어 있는 pickle 직렬화를 사용해 데이터를 이진 형식으로 저장하는 것
- pickle은 오래 보관할 필요가 없는 데이터일 경우에만 추천

> pickle은 오랜 시간이 지나도 안정적으로 데이터를 저장할 거라고 보장하기 힘든 문제가 있음 (라이브러리 버전이 올라갔을때 다시 읽어오지 못할 가능성이 존재)

```python
frame = pd.read_csv("examples/ex1.csv")

frame.to_pickle("examples/frame_pickle")

pd.read_pickle("examples/frame_pickle")

a	b	c	d	message
0	1	2	3	4	hello
1	5	6	7	8	world
2	9	10	11	12	foo
```

**HDF5 형식**

- 대량의 과학 계산용 배열 데이터를 저장하기 위해 고안된 파일 포맷
- Hierarchical Data Format (계층적 데이터 형식) 

```python
import numpy as np

frame = pd.DataFrame({"a" : np.random.randn(100)})
store = pd.HDFStore("mydata.h5")

store["obj1"] = frame
store["obj1_col"] = frame["a"]

store
# <class 'pandas.io.pytables.HDFStore'>
# File path: mydata.h5
```

- HDF5 파일에 포함된 객체는 파이썬 딕셔너리와 유사한 형식으로 사용가능 
- HDFStore는 "fixed"와 "table" 두 가지 저장 스키마를 지원
  - table 스키마가 일반적으로 더 느리지만 특별한 문법을 이용해 쿼리 연산을 지원

```python
store.put("obj2", frame, format="table")
# put은 store["obj2"] = frame과 동일하지만 저장 스키마를 지정하는 옵션을 제공 

store.select("obj2", where=["index >= 10 and index <= 15"])
```

<img src="https://user-images.githubusercontent.com/58063806/117005975-d04afa00-ad22-11eb-9895-56a96a1533a5.png" width=13% />

```python
frame.to_hdf("mydata.h5", "obj3", format="table")

pd.read_hdf("mydata.h5", "obj3", where=["index < 5"])
```

<img src="https://user-images.githubusercontent.com/58063806/117006647-a7773480-ad23-11eb-8da4-0e24bec632a9.png" width=13% />

**마이크로소프트 엑셀 파일**

데이터 로드

```python
1.
xlsx = pd.ExcelFile("examples/ex1.xlsx")
pd.read_excel(xlsx, "Sheet1")

2.
pd.read_excel("examples/ex1.xlsx", "Sheet1")
```

데이터 저장

```python
1.
writer = pd.ExcelWriter("examples/ex2.xlsx")
frame.to_excel(writer, "Sheet1")
writer.save()

2.
frame.to_excel("examples/ex2.xlsx")
```

위의 두 가지 방식들로 엑셀 파일 데이터 로드와 저장이 가능

#### 웹 API와 함께 사용

```python
import requests

url = "https://api.github.com/repos/pandas-dev/pandas/issues"
resp = requests.get(url)

resp
# <Response [200]>

data = resp.json()
# JSON 내용을 파이썬 딕셔너리 형태로 변환한 객체를 반환

issues = pd.DataFrame(data, columns=["number", "title", "labels", "state"])
issues.head()
```

<img src="https://user-images.githubusercontent.com/58063806/117008053-4a7c7e00-ad25-11eb-8ed9-deb52b9c0627.png" width=80%/>

#### 데이터베이스와 함께 사용

테이블 생성

```python
import sqlite3

query = """
    CREATE TABLE test
    (a VARCHAR(20), b VARCHAR(20),
    c REAL, d INTEGER);
"""

con = sqlite3.connect("mydata.sqlite")

con.execute(query)
con.commit()
```

데이터 입력

```python
data = [("Atlanta", "Georgia", 1.25, 6),
       ("Tallahassee", "Florida", 2.6, 3),
       ("Sacramento", "Califonia", 1.7, 5)]

stmt = "INSERT INTO test VALUES(?, ?, ?, ?)"

con.executemany(stmt, data)
con.commit()
```

데이터 조회

```python
cursor = con.execute("select * from test")
rows = cursor.fetchall()

rows

[('Atlanta', 'Georgia', 1.25, 6),
 ('Tallahassee', 'Florida', 2.6, 3),
 ('Sacramento', 'Califonia', 1.7, 5)]
```

```python
cursor.description

(('a', None, None, None, None, None, None),
 ('b', None, None, None, None, None, None),
 ('c', None, None, None, None, None, None),
 ('d', None, None, None, None, None, None))
```

```python
pd.DataFrame(rows, columns=[x[0] for x in cursor.description])
```

<img src="https://user-images.githubusercontent.com/58063806/117009614-e8247d00-ad26-11eb-84b4-5af4a152556a.png" width=25% />

SQLAlchemy

- 파이썬 SQL 툴킷인 SQLAlchemy 프로젝트는 SQL 데이터베이스 간의 일반적인 차이점을 추상화하여 제공

```python
import sqlalchemy as sqla

# SQLite 데이터베이스에 접속
db = sqla.create_engine("sqlite:///mydata.sqlite")

# 테이블에서 데이터를 읽어옴
pd.read_sql("select * from test", db)
```

