## 시계열

#### datetime

```python
from datetime import datetime

now = datetime.now()
now
# datetime.datetime(2021, 5, 29, 22, 57, 8, 521827)
# 연, 월, 일, 시, 분, 초, 마이크로초까지 지원

delta = datetime(2011, 1, 7) - datetime(2008, 6, 24, 8, 15)
delta
# datetime.timedelta(days=926, seconds=56700)
# 일, 초, 마이크로초 지원
```

- timedelta는 datetime 객체 간의 시간차이를 표현

```python
from datetime import timedelta

start = datetime(2011, 1, 7)
start + timedelta(12)
# datetime.datetime(2011, 1, 19, 0, 0)
start - 2 * timedelta(12)
# datetime.datetime(2010, 12, 14, 0, 0)
```

- timedelta를 datetime 객체에 더하거나 빼는 것도 가능

```python
stamp = datetime(2011, 1, 3)

str(stamp)
# '2011-01-03 00:00:00'
stamp.strftime("%Y-%m-%d")
# '2011-01-03'

datestrs = ['7/6/2011', '8/6/2011']
[datetime.strptime(x, "%m/%d/%Y") for x in datestrs]
# [datetime.datetime(2011, 7, 6, 0, 0), datetime.datetime(2011, 8, 6, 0, 0)]
```

- str, strftime으로 datetime을 문자열로 변환
- strptime으로 문자열을 datetime으로 변환

```python
from dateutil.parser import parse

parse("2011-01-03")
# datetime.datetime(2011, 1, 3, 0, 0)

parse("Jan 31, 1997 10:45 PM")
# datetime.datetime(1997, 1, 31, 22, 45)

# 날짜가 맨 앞에 오는 경우
parse('6/12/2011', dayfirst=True)
# datetime.datetime(2011, 12, 6, 0, 0)
```

- dateutil.parse를 이용해서 매번 포맷 규칙을 쓰지 않고 쉽게 문자열을 datetime으로 변환

```python
import pandas as pd

datestrs = ["2011-07-06 12:00:00", "2011-08-06 00:00:00"]
pd.to_datetime(datestrs)
# DatetimeIndex(['2011-07-06 12:00:00', '2011-08-06 00:00:00'], dtype='datetime64[ns]', freq=None)

idx = pd.to_datetime(datestrs + [None])
idx
# DatetimeIndex(['2011-07-06 12:00:00', '2011-08-06 00:00:00', 'NaT'], dtype='datetime64[ns]', freq=None)
```

- to_datetime은 표준 날짜 형식을 매우 빠르게 처리하고 누락된 값도 NaT로 처리

#### 시계열 기초

```python
dates = [datetime(2011, 1, 2), datetime(2011, 1, 5),
        datetime(2011, 1, 7), datetime(2011, 1, 8),
        datetime(2011, 1, 10), datetime(2011, 1, 12)]

# datetime객체들이 DatetimeIndex에 들어있는 시계열 데이터
ts = pd.Series(np.random.randn(6), index=dates)
ts
# 2011-01-02   -0.577712
# 2011-01-05   -1.231654
# 2011-01-07    1.747853
# 2011-01-08   -1.681626
# 2011-01-10    0.750115
# 2011-01-12    0.908471

ts + ts[::2]
# 2011-01-02   -1.155424
# 2011-01-05         NaN
# 2011-01-07    3.495706
# 2011-01-08         NaN
# 2011-01-10    1.500230
# 2011-01-12         NaN

stamp = ts.index[0]
stamp
# Timestamp('2011-01-02 00:00:00')
```

- 서로 다르게 색인된 **시계열 객체 간의 산술 연산은 자동으로 날짜(index)에 맞춰짐**
- DatetimeIndex의 스칼라 값은 pandas의 Timestamp 객체
  - Timestamp 객체는 datetime객체를 사용하는 어떤 곳에도 대체 사용이 가능

```python
stamp = ts.index[-2]
ts[stamp]
ts['1/10/2011']
ts['20110110']
# 0.7501151099342338

ts[datetime(2011, 1, 7):]
# 2011-01-07    1.747853
# 2011-01-08   -1.681626
# 2011-01-10    0.750115
# 2011-01-12    0.908471

ts["1/6/2011":'1/11/2011']
# 2011-01-07    1.747853
# 2011-01-08   -1.681626
# 2011-01-10    0.750115
```

- 라벨에 기반해서 데이터를 인덱싱
- 대부분의 시계열 데이터는 연대순으로 정렬되기 때문에 **날짜 문자열이나 datetime 혹은 타임스탬프를 이용해서 원본 시계열에 대한 뷰를 생성** 
  - 이에 대한 변경이 원본 데이터에도 반영

```python
ts.truncate(after='1/9/2011')
# 2011-01-02   -0.577712
# 2011-01-05   -1.231654
# 2011-01-07    1.747853
# 2011-01-08   -1.681626
ts.truncate(before='1/9/2011')
# 2011-01-10    0.750115
# 2011-01-12    0.908471
```

- 특정 시점 이전이나 이후의 데이터 추출
  - after - 해당 시점이후의 데이터를 자름 (해당 시점 이전의 데이터만 추출)
  - before - 해당 시점 이전의 데이터를 자름 (해당 시점 이후의 데이터만 추출)

```python
longer_ts = pd.Series(np.random.randn(1000),
                     index=pd.date_range('1/1/2000', periods=1000))

longer_ts
# 2000-01-01    3.080519
# 2000-01-02    0.798148
# 2000-01-03    1.630200
# 2000-01-04    2.332720
# 2000-01-05   -0.168789
#                 ...   
# 2002-09-22    0.753469
# 2002-09-23   -1.224349
# 2002-09-24   -0.156449
# 2002-09-25    0.361287
# 2002-09-26   -2.217907

longer_ts['2001']
# 2001-01-01   -0.812100
# 2001-01-02   -0.178954
# 2001-01-03    1.768009
# 2001-01-04    0.942992
# 2001-01-05   -0.464456
#                 ...   
# 2001-12-27   -1.800393
# 2001-12-28   -1.373362
# 2001-12-29    0.344692
# 2001-12-30    1.399496
# 2001-12-31   -0.531002

# 월까지 넘긴 경우
# longer_ts['2001-05']
```

- 긴 시계열에서는 연, 월만 넘겨서 데이터의 일부 구간만 선택가능

#### 날짜 범위, 빈도

```python
# 각 월의 둘째주 월요일에 해당하는 날짜만 포함
pd.date_range("2020-01-01", "2020-12-01", freq="WOM-2MON")

# DatetimeIndex(['2020-01-13', '2020-02-10', '2020-03-09', '2020-04-13',
#               '2020-05-11', '2020-06-08', '2020-07-13', '2020-08-10',
#               '2020-09-14', '2020-10-12', '2020-11-09'],
#              dtype='datetime64[ns]', freq='WOM-2MON')
```

- 빈도값에 따라 포함되는 날짜들을 다양하게 할 수 있음

```python
pd.date_range("2020-05-02 12:56:31", periods=5)

# DatetimeIndex(['2020-05-02 12:56:31', '2020-05-03 12:56:31',
#               '2020-05-04 12:56:31', '2020-05-05 12:56:31',
#               '2020-05-06 12:56:31'],
#              dtype='datetime64[ns]', freq='D')

pd.date_range("2020-05-02 12:56:31", periods=5, normalize=True)

# DatetimeIndex(['2020-05-02', '2020-05-03', '2020-05-04', '2020-05-05',
#               '2020-05-06'],
#              dtype='datetime64[ns]', freq='D')
```

- date_range는 기본적으로 시작 시간이나 종료 시간의 타임스탬프를 보존
- normalize 옵션을 이용해 자정에 맞추어 타임스탬프 정규화 가능 

```python
from pandas.tseries.offsets import Hour, Minute

hour = Hour(1) + Minute(30)

pd.date_range("2000-01-01", "2000-01-03 23:59", freq=hour)
# DatetimeIndex(['2000-01-01 00:00:00', '2000-01-01 01:30:00',
#               '2000-01-01 03:00:00', '2000-01-01 04:30:00',
#               '2000-01-01 06:00:00', '2000-01-01 07:30:00',
#               '2000-01-01 09:00:00', '2000-01-01 10:30:00',
#               '2000-01-01 12:00:00', '2000-01-01 13:30:00',
#               '2000-01-01 15:00:00', '2000-01-01 16:30:00',
#               '2000-01-01 18:00:00', '2000-01-01 19:30:00',
#               '2000-01-01 21:00:00', '2000-01-01 22:30:00'],
#              dtype='datetime64[ns]', freq='90T')

# pd.date_range("2000-01-01", "2000-01-03 23:59", freq="1h30min")과 동일한 결과
```

- 기본 빈도는 "M"(월별), "H"(시간별)같은 짧은 문자열로 이루어짐
- 빈도에는 날짜 오프셋이라고 불리는 객체를 사용 가능

#### 날짜 시프트

```python
ts = pd.Series(np.random.randn(4),
              index=pd.date_range("1/1/2000", periods=4, freq="M"))
ts
# 2000-01-31   -0.817332
# 2000-02-29   -0.442260
# 2000-03-31    0.104918
# 2000-04-30    0.433530

ts.shift(2)
# 2000-01-31         NaN
# 2000-02-29         NaN
# 2000-03-31   -0.817332
# 2000-04-30   -0.442260
```

- 위와 같이 빈도를 명시하지않고 그냥 shift를 하게 되면 데이터에 결측치가 발생

```python
# 현 시점에서 다다음달의 마지막 날
ts.shift(2, freq="M")
# 2000-03-31   -0.817332
# 2000-04-30   -0.442260
# 2000-05-31    0.104918
# 2000-06-30    0.433530

# 현 시점에서 2일 후
ts.shift(2, freq="D")
# 2000-02-02   -0.817332
# 2000-03-02   -0.442260
# 2000-04-02    0.104918
# 2000-05-02    0.433530

# 현 시점에서 90분 후
ts.shift(1, freq="90T")
# 2000-01-31 01:30:00   -0.817332
# 2000-02-29 01:30:00   -0.442260
# 2000-03-31 01:30:00    0.104918
# 2000-04-30 01:30:00    0.433530
```

- 여러가지 빈도수를 명시함으로써 알맞게 날짜를 이동시킴

```python
from pandas.tseries.offsets import Day, MonthEnd

now = datetime(2011, 11, 17)
now + MonthEnd()
# Timestamp('2011-11-30 00:00:00')

offset = MonthEnd()
offset.rollforward(now)
# Timestamp('2011-11-30 00:00:00')

offset.rollback(now)
# Timestamp('2011-10-31 00:00:00')
```

- MonthEnd() 같은 앵커드 오프셋은 rollforward, rollback으로 날짜를 앞으로 밀거나 뒤로 당길 수 있음

```python
ts = pd.Series(np.random.randn(20),
         index=pd.date_range('1/15/2000', periods=20, freq="4d"))
ts
# 2000-01-15    1.552756
# 2000-01-19   -0.218795
# 2000-01-23   -0.776800
# 2000-01-27    1.815139
# 2000-01-31   -0.372706
# 2000-02-04   -0.329045
# 2000-02-08    0.803803
# 2000-02-12    0.259822
# 2000-02-16    0.322312
# 2000-02-20   -0.570612
# 2000-02-24    0.907511
# 2000-02-28   -0.241425
# 2000-03-03    0.410682
# 2000-03-07    0.986748
# 2000-03-11   -0.650990
# 2000-03-15   -0.425525
# 2000-03-19   -0.970835
# 2000-03-23    1.125645
# 2000-03-27   -0.041630
# 2000-03-31   -1.067134

ts.groupby(offset.rollforward).mean()
# 2000-01-31    0.399919
# 2000-02-29    0.164624
# 2000-03-31   -0.079130
```

- 앵커드 오프셋의 rollforward 메서들를 groupby와 함께 사용해서 월별 평균치를 구함

#### 리샘플링과 빈도 변환

- 리샘플링은 시계열의 빈도를 변환하는 과정
  - 다운샘플링 : 상위 빈도의 데이터를 하위 빈도로 집계하는 것
  - 업샘플링 : 하위 빈도의 데이터를 상위 빈도로 집계하는 것 

```python
rng = pd.date_range("2001-01-01", periods=100, freq="D")
ts = pd.Series(np.random.randn(len(rng)), index=rng)
ts
# 2001-01-01   -0.886547
# 2001-01-02    0.037595
# 2001-01-03   -0.292800
# 2001-01-04    0.902966
# 2001-01-05    2.117005
#                 ...   
# 2001-04-06    1.265406
# 2001-04-07    0.708420
# 2001-04-08    1.790946
# 2001-04-09   -2.772775
# 2001-04-10    0.157699

ts.resample("M").mean()
# 2001-01-31    0.198828
# 2001-02-28   -0.292078
# 2001-03-31   -0.055672
# 2001-04-30    0.238571

ts.resample("M", kind="period").mean()
# 2001-01    0.198828
# 2001-02   -0.292078
# 2001-03   -0.055672
# 2001-04    0.238571
```

- freq 별로 데이터를 그룹짓고 mean 함수를 적용
  - kind : period(기간) 혹은 timestamp 별로 집계할 것인지 구분, 기본값은 시계열의 색인 종류와 동일 

**다운샘플링**

```python
rng = pd.date_range("2000-01-01", periods=12, freq="T")
ts = pd.Series(np.arange(12), index=rng)
# 2000-01-01 00:00:00     0
# 2000-01-01 00:01:00     1
# 2000-01-01 00:02:00     2
# 2000-01-01 00:03:00     3
# 2000-01-01 00:04:00     4
# 2000-01-01 00:05:00     5
# 2000-01-01 00:06:00     6
# 2000-01-01 00:07:00     7
# 2000-01-01 00:08:00     8
# 2000-01-01 00:09:00     9
# 2000-01-01 00:10:00    10
# 2000-01-01 00:11:00    11

ts.resample('5min', closed="right").sum()
# 1999-12-31 23:55:00     0
# 2000-01-01 00:00:00    15
# 2000-01-01 00:05:00    40
# 2000-01-01 00:10:00    11

ts.resample('5min', closed="left").sum()
# 2000-01-01 00:00:00    10
# 2000-01-01 00:05:00    35
# 2000-01-01 00:10:00    21

ts.resample('5min', closed="right", label="right").sum()
# 2000-01-01 00:00:00     0
# 2000-01-01 00:05:00    15
# 2000-01-01 00:10:00    40
# 2000-01-01 00:15:00    11
```

- closed="right" : 시작값을 그룹의 오른쪽 끝에 포함
  - **EX) 1999-12-31 12:59:55 ~ 2000-01-01 00:00:00**
- closed="left" : 시작값을 그룹의 왼쪽 끝에 포함
  - **EX) 2000-01-01 00:00:00 ~ 2000-01-01 00:04:00**
- label="right" : 각 그룹의 오른쪽 끝 값을 라벨로 사용

```python
ts.resample("5min", closed="right", label="right", loffset="-1s").sum()
# 1999-12-31 23:59:59     0
# 2000-01-01 00:04:59    15
# 2000-01-01 00:09:59    40
# 2000-01-01 00:14:59    11
```

- 반환된 결과의 색인을 특정 크기만큼 이동시키는 경우에는 loffset 메서드에 문자열이나 날짜 오프셋을 넘겨줌

**OHLC 리샘플링**

```python
ts.resample("5min").ohlc()
```

<img src="https://user-images.githubusercontent.com/58063806/120204426-c2c25a80-c263-11eb-97f4-ade0c0badb37.png" width=40% />

- 금융분야에서 시계열 데이터를 집계하는 흔한 방식으로 **시가, 고가, 저가, 종가에 대한 값을 계산해서 반환**

**업샘플링과 보간**

<img src="https://user-images.githubusercontent.com/58063806/120205216-a83cb100-c264-11eb-9401-caea104cecb2.png" width=40% />

```python
df_daily = frame.resample("D").asfreq()
df_daily
```

<img src="https://user-images.githubusercontent.com/58063806/120205310-c86c7000-c264-11eb-8027-c63c300b3a9a.png" width=40% />

- 상위 빈도로 리샘플링한 결과 사이에 결측치들이 생성됨

```python
frame.resample("D").ffill()
# frame.resample("D").ffill(limit=2) 01-06, 01-07 값만 채워짐
```

<img src="https://user-images.githubusercontent.com/58063806/120205516-01a4e000-c265-11eb-9f0e-6ce2fe81ab1e.png" width=40%/>

- ffill(이전의 값으로 채워줌)로 보간을 수행
  - limit 속성으로 보간법을 적용할 범위를 지정할 수 있음

**기간 리샘플링**

데이터 일부

<img src="https://user-images.githubusercontent.com/58063806/120205897-77a94700-c265-11eb-96b2-63357a424b72.png" width=40% />

```python
annual_frame = frame.resample("A-DEC").mean()
annual_frame
```

<img src="https://user-images.githubusercontent.com/58063806/120206558-4e3ceb00-c266-11eb-881b-6f2503d0021a.png" width=40% />

```python
annual_frame.resample("Q-DEC", convention="end").ffill()
```

<img src="https://user-images.githubusercontent.com/58063806/120206970-ca373300-c266-11eb-94e8-f1dfbc04ccdd.png" width=40% />

- 업샘플링은 리샘플링 전에 새로운 빈도에서 구간의 끝을 어느 쪽에 두어야할지 convention 인자를 통해 결정해야함
  - convention="start"가 기본값
  - <img src="https://user-images.githubusercontent.com/58063806/120207177-13878280-c267-11eb-9b43-16d8491aeb68.png" width=40% />

#### 이동창 함수

```python
close_px_all = pd.read_csv("examples/stock_px_2.csv", parse_dates=True, index_col=0)

close_px = close_px_all[["AAPL", "MSFT", "XOM"]]
# 매 영업일 빈도로 리샘플링 후 보간을 적용
close_px = colse_px.resample("B").ffill()
close_px.AAPL.plot()
close_px.AAPL.rolling(250).mean().plot()
```

전체 AAPL 주가 데이터와 250일의 이동평균

<img src="https://user-images.githubusercontent.com/58063806/120207919-f1dacb00-c267-11eb-806d-6a63d369f7d5.png" width=50%/>

- rolling은 250일 크기의 움직이는 창을 통해 그룹핑할 수 있는 객체를 생성

```python
appl_std250 = close_px.AAPL.rolling(250, min_periods=10).std()
appl_std250.plot()
```

AAPL의 250일 일별 수익 표준편차

<img src="https://user-images.githubusercontent.com/58063806/120209115-403c9980-c269-11eb-9a69-ee5b412e087d.png" width=50% />

- min_periods : 최소 10개의 데이터가 있으면 집계함수를 적용 (default = 1)

```python
close_px.rolling("20D").mean()
```

- 빈도가 불규칙한 시계열일 경우 고정 크기의 기간 지정 문자열을 넘겨서 호출 가능

**확장창 평균** **- 시계열의 시작 지점에서부터 창의 크기가 시계열의 전체 크기가 될 때까지 점점 창의 크기를 늘림**

**지수 가중 함수**

- 감쇠인자 상수에 좀 더 많은 가중치를 줘서 다 최근 값을 관찰
- **최근 값에 좀 더 많은 가중치**를 두는 방법으로 균등 가중 방식에 비해 좀 더 **빠르게 변화를 수용** 

```python
import matplotlib.pyplot as plt

aapl_px = close_px.AAPL['2006':'2007']
ma60 = aapl_px.rolling(30, min_periods=20).mean()
# ewm - 지수 이동 평균 (span은 윈도우 사이즈)
ewma60 = aapl_px.ewm(span=30).mean()
ma60.plot(style="b--", label="Simple MA")
ewma60.plot(style="r-", label="EW MA")
plt.legend()
plt.show()
```

<img src="https://user-images.githubusercontent.com/58063806/120212492-0372a180-c26d-11eb-9c01-1b32bd4308ff.png" width=50% />

**이진 이동창 함수**

- 상관관계와 공분산 같은 몇몇 통계 연산은 두 개의 시계열을 필요로 함

```python
spx_px = close_px_all["SPX"]
spx_rets = spx_px.pct_change()
returns = close_px.pct_change()
corr = returns.rolling(125, min_periods=100).corr(spx_rets)
corr.plot()
```

6개월 수익과 S&P 500 지수의 상관관계 

<img src="https://user-images.githubusercontent.com/58063806/120213261-f0140600-c26d-11eb-824d-871a42f0b537.png" width=50% />

**사용자 정의 이동창 함수**

```python
from scipy.stats import percentileofscore

score_at_2percent = lambda x: percentileofscore(x, 0.02)
result = returns.AAPL.rolling(250).apply(score_at_2percent)
result.plot()
```

<img src="https://user-images.githubusercontent.com/58063806/120214001-d7582000-c26e-11eb-8c5b-471ea961a7f8.png" width=50% />

- 2%의 AAPL 수익률에 대한 백분위 점수 
  - 수익률이 2%에 가까워 질 수록 백분위 점수는 높아짐 

